{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene linker pipeline for \"Chromatin looping links target genes with genetic risk loci for dermatological traits\"\n",
    "\n",
    "preprint available at https://www.biorxiv.org/content/10.1101/2020.03.05.973271v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import all libraries needed for analysis.\n",
    "Suggested using the Conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import pybedtools as pbed \n",
    "import helpers.gene_link\n",
    "import subprocess as sub\n",
    "import math\n",
    "import statistics\n",
    "import itertools\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "os.makedirs(\"/mnt/iusers01/jw01/mdefscs4/scratch/temp_pybedtools/\", exist_ok = True)\n",
    "pbed.helpers.set_tempdir(\"/mnt/iusers01/jw01/mdefscs4/scratch/temp_pybedtools/\")\n",
    "bed_genome_file = \"/mnt/iusers01/jw01/mdefscs4/hg38.genome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings. leave as it is for same results as paper\n",
    "\n",
    "# filter genes by RNA-seq?\n",
    "RNA_seq_filter = True\n",
    "\n",
    "# filter SNPs by active peak?\n",
    "SNP_filter_peak_OE = False\n",
    "SNP_filter_peak_overlapping = True\n",
    "\n",
    "# add overlapping genes to results?\n",
    "Append_overlapping = True\n",
    "\n",
    "# do you have TADs?\n",
    "report_TADs = True\n",
    "\n",
    "# output folder\n",
    "output_folder = \"../example_results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all GWAS files\n",
    "\n",
    "format required:\n",
    "\n",
    "chr  start  end(start+1)  score  snpid_LOCI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of GWAS annotation\n",
    "GWAS_loc = \"../datasets/gwas\"\n",
    "\n",
    "GWAS_files = [\"bowes_stuart.ld.hg38.bed\",\"duffy.ld.hg38.bed\",\"eczema_no_hla.ld.hg38.bed\",\"elena.ld.hg38.bed\",\"tsoi2017_LD_0.8_hg38.bed\"]\n",
    "\n",
    "snp_names = [\"PsA\", \"Ps\", \"at_derm\", \"melanoma\", \"sclerosis\"]\n",
    "\n",
    "snp_dfs = {key:pd.read_csv(os.path.join(GWAS_loc,value), sep=\"\\t\",header=None) for (key,value) in zip(snp_names,GWAS_files)}\n",
    "for x in snp_dfs.values():\n",
    "    x.columns = \"chr start end name score\".split()\n",
    "    x[\"loci\"] = x[\"name\"].str.split(\"_\").str[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all loops and peaks files needed.\n",
    "\n",
    "Use processed files with HiC-pro and then use FitHiChIP and HiChIP-peaks to identify loops and peaks.\n",
    "\n",
    "We use the stringent, merged interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the loops files\n",
    "loops_loc = \"../datasets/loops\"\n",
    "\n",
    "# name your files with FULL_NAME and if you have replicates use FULL_NAME_N with N = 1,2... (currently max 6 but you can change code down)\n",
    "# avoid naming samples with a name that is a substring of another sample (e.g. T_cell and T_cell_th17)\n",
    "names = [\"hacat_stim_1\",\"hacat_stim_2\",\"hacat_unstim_1\",\"hacat_unstim_2\",\"myla_1\",\"myla_2\",\"naive_T_1\",\"naive_T_2\",\"GM12878\",\"hacat_stim\",\"hacat_unstim\",\"myla\",\"naive_T\",]\n",
    "# give the names of the full(combined samples)\n",
    "full_names = [\"GM12878\",\"hacat_stim\",\"hacat_unstim\",\"myla\",\"naive_T\"]\n",
    "\n",
    "# give list of files IN THE SAME ORDER as the names provided above\n",
    "files = [\"HaCat_27ac_st_rep1_helen_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"HaCat_27ac_st_rep2_helen_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"HaCat_27ac_unst_rep1_helen_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"HaCat_27ac_unst_rep2_helen_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"MyLa_27ac_rep1_helen_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"MyLa_27ac_rep2_helen_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"NaiveT_27ac_B2_mumbach_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"NaiveT_27ac_B3_mumbach_stringent_merged_interactions_Q0.01.bed\",\n",
    "         \"GM12878_H3K27ac_mumbach_combined_stringent_merged_interactions_Q0.01.bed\",\n",
    "        \"HaCaT_st_27ac_helen_combined_stringent_merged_interactions_Q0.01.bed\",\n",
    "        \"HaCaT_unst_27ac_helen_combined_stringent_merged_interactions_Q0.01.bed\",\n",
    "        \"MyLa_27ac_helen_combined_stringent_merged_interactions_Q0.01.bed\",\n",
    "        \"Naive_Tcells_H3K27ac_mumbach_combined_stringent_merged_interactions_Q0.01.bed\",]\n",
    "\n",
    "dict_loops = {key:pd.read_csv(os.path.join(loops_loc,value), sep=\"\\t\") for (key,value) in zip(names,files)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all peaks datasets\n",
    "# position of the peaks files\n",
    "peaks_loc = \"../datasets/peaks\"\n",
    "\n",
    "# provide the list of file names in the same order as above\n",
    "peaks_fn = [\"HaCat_27ac_st_rep1_helenpeaks.bed\", \"HaCat_27ac_st_rep2_helenpeaks.bed\", \"HaCat_27ac_unst_rep1_helenpeaks.bed\", \"HaCat_27ac_unst_rep2_helenpeaks.bed\",\n",
    "            \"MyLa_27ac_rep1_helenpeaks.bed\", \"MyLa_27ac_rep2_helenpeaks.bed\", \"NaiveT_27ac_B2_mumbachpeaks.bed\", \"NaiveT_27ac_B3_mumbachpeaks.bed\",\n",
    "            \"GM12878_H3K27ac_mumbach_combinedpeaks.bed\",\"HaCaT_st_27ac_helen_combinedpeaks.bed\",\"HaCaT_unst_27ac_helen_combinedpeaks.bed\",\"MyLa_27ac_helen_combinedpeaks.bed\",\n",
    "            \"Naive_Tcells_H3K27ac_mumbach_combinedpeaks.bed\"]\n",
    "\n",
    "dict_peaks = {key:pd.read_csv(os.path.join(peaks_loc,value), sep=\"\\t\", header=None) for (key,value) in zip(names,peaks_fn)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare TAD files.\n",
    "\n",
    "TADs in this script have been called using OnTAD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for which samples are TADs available?\n",
    "tad_samples = [\"hacat_stim\",\"hacat_unstim\",\"myla\"]\n",
    "\n",
    "tads_loc = \"../datasets/TADs\"\n",
    "tad_files = [\"OnTAD_hacat_stim_all_chr_sorted.bed.gz\",\n",
    "        \"OnTAD_hacat_unstim_all_chr_sorted.bed.gz\",\n",
    "        \"OnTAD_myla_all_chr_sorted.bed.gz\"]\n",
    "# dict to map color of the tad to the tad level reported by ontad\n",
    "color_map = {'127,201,127':2, '190,174,212':3, '253,192,134':4, '255,0,0':5, '56,108,176':1}\n",
    "\n",
    "tads_dfs_merged = {key:pd.read_csv(os.path.join(tads_loc,x) , sep=\"\\t\", header=None, converters={8:lambda x: color_map[x]}) for (key,x) in zip(tad_samples,tad_files)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare RNA-seq files.\n",
    "\n",
    "Script only links genes that are transcribed in the cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_seq_location = \"../datasets/RNA-seq/Expression_TPM.csv\"\n",
    "expressed_genes = pd.read_csv(rna_seq_location, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of actual script\n",
    "All code belove has been reassembled to work with most conditions above. If you need help please contact me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotation for transcripts\n",
    "try:\n",
    "    gtf_annotation_df = pd.read_pickle(\"../datasets/references/gencode_gtf.pickle\")\n",
    "except FileNotFoundError:\n",
    "    print(\"could not find pickled version of gencode reference, recreating new (slow)\")\n",
    "    import helpers.gtf_reader\n",
    "    gtf_annotation = \"../datasets/references/gencode.v29.primary_assembly.annotation.gtf.gz\"\n",
    "    gtf_annotation_df = helpers.gtf_reader.gtf_dataframe(gtf_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get transcripts, reformat gene_id and identify start site.\n",
    "gtf_transcripts = gtf_annotation_df[(gtf_annotation_df[\"feature\"] == \"transcript\") & (gtf_annotation_df[\"transcript_type\"] == \"protein_coding\")].dropna(axis=1, how='all')\n",
    "gtf_transcripts[\"gene_id\"] = gtf_transcripts[\"gene_id\"].str.split(\".\").str[0]\n",
    "gtf_transcripts[\"transcript_id\"] = gtf_transcripts[\"transcript_id\"].str.split(\".\").str[0]\n",
    "gtf_transcripts[\"TSS_start\"] = gtf_transcripts.apply(lambda x: int(x[\"start\"]) if x[\"strand\"] == \"+\" else int(x[\"end\"]) ,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link genes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link all genes\n",
    "\n",
    "def _cf_helper(x):\n",
    "    return helpers.gene_link.link_genes(x, dict_loops,dict_peaks,gtf_transcripts, SNP_filter_peak_OE, SNP_filter_peak_overlapping)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers = 8) as executor:\n",
    "    result = list(executor.map(_cf_helper, snp_dfs.values()))\n",
    "    OtherEnd_genes = {k:v[0] for k,v in zip(snp_dfs, result)}\n",
    "    Overlapping_genes = {k:v[1] for k,v in zip(snp_dfs, result)}\n",
    "\n",
    "\n",
    "# Unparellized version if you need it\n",
    "# OtherEnd_genes = {}\n",
    "# Overlapping_genes = {}\n",
    "\n",
    "# for name, x in snp_dfs.items():\n",
    "#     OtherEnd_genes[name], Overlapping_genes[name] = helpers.gene_link.link_genes(x,dict_loops,dict_peaks,gtf_transcripts, SNP_filter_peak_OE, SNP_filter_peak_overlapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_set(x):\n",
    "    # helper function to link snps in a set for pandas\n",
    "    l = []\n",
    "    for i in x:\n",
    "        if not pd.isna(i):\n",
    "            l.extend(i)\n",
    "    if len(set(l)) == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return set(l)\n",
    "\n",
    "# mapping between RNA-seq and samples\n",
    "sample_cond = {}\n",
    "for sample in expressed_genes.columns:\n",
    "    if sample in names:\n",
    "        sample_cond[sample] = sample\n",
    "        for i in names:\n",
    "            if sample in i:\n",
    "                sample_cond[i] = sample\n",
    "    \n",
    "# group originating snps together and filter genes based on expression\n",
    "agg_act = {**dict.fromkeys(names, 'min'),**dict.fromkeys([\"transcript_\" + x for x in names],join_set),**dict.fromkeys([\"linked_SNP_\" + x for x in names],join_set)}\n",
    "genes_dfs = {}\n",
    "for snp_name in Overlapping_genes:\n",
    "    if RNA_seq_filter:\n",
    "        for sample in names:\n",
    "            OtherEnd_genes[snp_name].loc[OtherEnd_genes[snp_name][\"gene_id\"].isin(expressed_genes[expressed_genes[sample_cond[sample]] < 1].index),[sample,\"transcript_\" + sample, \"linked_SNP_\" + sample]] = np.nan\n",
    "            Overlapping_genes[snp_name].loc[Overlapping_genes[snp_name][\"gene_id\"].isin(expressed_genes[expressed_genes[sample_cond[sample]] < 1].index),[sample,\"transcript_\" + sample, \"linked_SNP_\" + sample]] = np.nan\n",
    "    OtherEnd_genes[snp_name] = OtherEnd_genes[snp_name].dropna(how=\"all\",subset=names)\n",
    "    Overlapping_genes[snp_name] = Overlapping_genes[snp_name].dropna(how=\"all\",subset=names)\n",
    "    if Append_overlapping:\n",
    "        genes_dfs[snp_name] = pd.concat((OtherEnd_genes[snp_name],Overlapping_genes[snp_name]),sort=False)\n",
    "    else:\n",
    "        genes_dfs[snp_name] = OtherEnd_genes[snp_name]\n",
    "    genes_dfs[snp_name] = genes_dfs[snp_name].groupby(\"gene_id\",as_index = False).agg(agg_act)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save processed intermediate data\n",
    "for SNP, df_OE in OtherEnd_genes.items():\n",
    "    df_OE.merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates()).to_csv(\n",
    "    os.path.join(output_folder, \"genes_OE_\" + SNP + \".csv\"))\n",
    "    df_OE.merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates()).to_pickle(\n",
    "    os.path.join(output_folder, \"genes_OE_\" + SNP + \".pkl\"))\n",
    "for SNP, df_Over in Overlapping_genes.items():\n",
    "    df_Over.merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates()).to_csv(\n",
    "    os.path.join(output_folder, \"genes_overlapping_\" + SNP + \".csv\"))\n",
    "    df_Over.merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates()).to_pickle(\n",
    "    os.path.join(output_folder, \"genes_overlapping_\" + SNP + \".pkl\"))\n",
    "for SNP, value in genes_dfs.items():\n",
    "    value[[\"gene_id\"] + names].merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates()).to_csv(\n",
    "    os.path.join(output_folder, \"genes_linked_\" + SNP + \".csv\"))\n",
    "    value[[\"gene_id\"] + names].merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates()).to_pickle(\n",
    "    os.path.join(output_folder, \"genes_linked_\" + SNP + \".pkl\"))\n",
    "for SNP in genes_dfs:\n",
    "    genes_dfs[SNP] = genes_dfs[SNP].merge(gtf_transcripts[[\"gene_id\", \"gene_name\"]].drop_duplicates())\n",
    "    genes_dfs[SNP].to_csv(os.path.join(output_folder, \"genes_linked_with_info_\" + SNP + \".csv\"))\n",
    "    genes_dfs[SNP].to_pickle(os.path.join(output_folder, \"genes_linked_with_info_\" + SNP + \".pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link TADs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_tad_level(genes_df, snp_df):\n",
    "    def _get_TAD(gene_coord, loci_start, loci_end, cond):\n",
    "        cond = cond.rstrip(\"_1\")\n",
    "        cond = cond.rstrip(\"_2\")\n",
    "        cond = cond.rstrip(\"_3\")\n",
    "        cond = cond.rstrip(\"_4\")\n",
    "        cond = cond.rstrip(\"_5\")\n",
    "        cond = cond.rstrip(\"_6\")\n",
    "        tad_df = tads_dfs_merged[cond]\n",
    "        tads_gene = tad_df[(tad_df[0] == gene_coord[0]) & (tad_df[1] <= int(gene_coord[1]) - 40000) & (tad_df[2] >= int(gene_coord[2]) + 40000)]\n",
    "        tads = tads_gene[(tads_gene[1] < loci_end + 40000) & (tads_gene[2] > loci_start - 40000)]\n",
    "        if len(tads.index) == 0:\n",
    "            if len(tads_gene.index) == 0:\n",
    "                return np.nan\n",
    "            return 0\n",
    "        return tads.loc[tads[8].idxmax()][8]\n",
    "    \n",
    "    def _get_gene_coord(gene):\n",
    "        transcripts = gtf_transcripts[gtf_transcripts[\"gene_id\"] == gene]\n",
    "        return [transcripts[\"seqname\"].iloc[0], transcripts[\"start\"].min(), transcripts[\"end\"].max()]\n",
    "    \n",
    "    def _get_loci_coords(row_gene):\n",
    "        gene_coord = _get_gene_coord(row_gene[\"gene_id\"])\n",
    "        locis = []\n",
    "        for i in names:\n",
    "            # for each cell type, if it has been linked\n",
    "            if type(row_gene[\"linked_SNP_\" + i]) == set:\n",
    "                loci = set([x.split(\"_\")[-1] for x in row_gene[\"linked_SNP_\" + i]])\n",
    "                locis.extend(list(loci))\n",
    "                if i in conditions_with_TADs:\n",
    "                    row_gene[\"TAD_level_\" + i] = {}\n",
    "                    for j in range(len(loci)):\n",
    "                        t = snp_df[snp_df[\"loci\"] == list(loci)[j]]\n",
    "                        loci_start = t[\"start\"].min()\n",
    "                        loci_end = t[\"end\"].max()\n",
    "                        tad_level = _get_TAD(gene_coord, loci_start, loci_end, i)\n",
    "                        row_gene[\"TAD_level_\" + i][list(loci)[j]] = tad_level\n",
    "        row_gene[\"locis\"] = list(loci)\n",
    "        return row_gene\n",
    "    \n",
    "    def _get_TAD_level_final(row, cond, loci):\n",
    "        cols = [x for x in row.index if \"TAD_level_\" + cond in x]\n",
    "        vals = []\n",
    "        for i in cols:\n",
    "            if (type(row[i]) != float) and (loci in row[i].keys()):\n",
    "                vals.append(row[i][loci])\n",
    "        if vals != []:\n",
    "            return min(vals)\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    conditions_with_TADs = [x for x in names if any(s in x for s in tad_samples)]\n",
    "    \n",
    "    coords = genes_df.apply(_get_loci_coords, axis = 1)\n",
    "    df = pd.DataFrame()\n",
    "    for idx, row in coords.iterrows():\n",
    "        for loci in row[\"locis\"]:\n",
    "            TAD = {}\n",
    "            for cond in tad_samples:\n",
    "                TAD[\"TAD_level_\" + cond] = _get_TAD_level_final(row, cond, loci)\n",
    "            up_df = {\"loci\":loci}\n",
    "            up_df.update(TAD)\n",
    "            df = df.append(row[genes_df.columns.tolist()].append(pd.Series(up_df)), ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_dfs_TADs = {}\n",
    "for disease in snp_names:\n",
    "    genes_dfs_TADs[disease] = identify_tad_level(genes_dfs[disease], snp_dfs[disease],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hacat_stim', 'hacat_unstim', 'myla', 'naive_T']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_with_replicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate nice looking table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined</th>\n",
       "      <th>GM12878</th>\n",
       "      <th>hacat_stim</th>\n",
       "      <th>hacat_unstim</th>\n",
       "      <th>myla</th>\n",
       "      <th>naive_T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loci</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>rs12044149</td>\n",
       "      <td>SLC35D1; GADD45A; PDE4B; MIER1</td>\n",
       "      <td>SLC35D1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SLC35D1 (all); GADD45A (naive_T_2 only); PDE4B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs12884468</td>\n",
       "      <td>PPP2R3C; KIAA0391; PSMA6</td>\n",
       "      <td></td>\n",
       "      <td>PPP2R3C (hacat_stim_2,hacat_stim only), TAD le...</td>\n",
       "      <td>PPP2R3C (hacat_unstim_2,hacat_unstim only), TA...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs2020854</td>\n",
       "      <td>CS (overlapping); ERBB3; BAZ2A; IL23A; ATP5F1B...</td>\n",
       "      <td>CS; BAZ2A; IL23A; ATP5F1B; PTGES3; TIMELESS; G...</td>\n",
       "      <td>CS (all), TAD level:3; BAZ2A (hacat_stim_2 onl...</td>\n",
       "      <td>CS (all), TAD level:3; TIMELESS (hacat_unstim_...</td>\n",
       "      <td>CS (all), TAD level:1; IL23A (myla only), TAD ...</td>\n",
       "      <td>CS (all); ERBB3 (all); BAZ2A (all); IL23A (all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs33980500</td>\n",
       "      <td>REV3L; TRAF3IP2; MFSD4B</td>\n",
       "      <td>REV3L; TRAF3IP2</td>\n",
       "      <td>REV3L (hacat_stim_2,hacat_stim only), TAD leve...</td>\n",
       "      <td>REV3L (hacat_unstim_2,hacat_unstim only), TAD ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs34725611</td>\n",
       "      <td>ICAM1; TYK2</td>\n",
       "      <td>ICAM1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>ICAM1 (myla_1,myla only), TAD level:1; TYK2 (m...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs4921482</td>\n",
       "      <td>TTC1</td>\n",
       "      <td>TTC1</td>\n",
       "      <td>TTC1 (hacat_stim only), TAD level:1</td>\n",
       "      <td>TTC1 (hacat_unstim only), TAD level:1</td>\n",
       "      <td></td>\n",
       "      <td>TTC1 (naive_T_1,naive_T only)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs715285</td>\n",
       "      <td>P4HA2; IRF1; PDLIM4; RAPGEF6; SLC22A4; SLC22A5...</td>\n",
       "      <td></td>\n",
       "      <td>P4HA2 (hacat_stim only), TAD level:2; RAPGEF6 ...</td>\n",
       "      <td>IRF1 (hacat_unstim only), TAD level:1; PDLIM4 ...</td>\n",
       "      <td>IRF1 (all), TAD level:1; SLC22A5 (myla only), ...</td>\n",
       "      <td>FNIP1 (naive_T only)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs7552167</td>\n",
       "      <td>STPG1; NIPAL3; RCAN3; SRRM1; IL22RA1; GRHL3; C...</td>\n",
       "      <td></td>\n",
       "      <td>STPG1 (all), TAD level:4; NIPAL3 (all), TAD le...</td>\n",
       "      <td>STPG1 (all), TAD level:3; NIPAL3 (all), TAD le...</td>\n",
       "      <td>STPG1 (all), TAD level:3; NIPAL3 (all), TAD le...</td>\n",
       "      <td>STPG1 (all); NIPAL3 (naive_T only); SRRM1 (all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>rs76956521</td>\n",
       "      <td>CD74; NDST1; RBM22; DCTN4; TNIP1 (overlapping)...</td>\n",
       "      <td>CD74; TNIP1; RPS14; ATOX1</td>\n",
       "      <td>NDST1 (hacat_stim only), TAD level:1; TNIP1 (h...</td>\n",
       "      <td>TNIP1 (hacat_unstim_2,hacat_unstim only), TAD ...</td>\n",
       "      <td>CD74 (myla_1,myla only), TAD level:outside tad...</td>\n",
       "      <td>CD74 (all); DCTN4 (naive_T_1,naive_T only); TN...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     combined  \\\n",
       "loci                                                            \n",
       "rs12044149                     SLC35D1; GADD45A; PDE4B; MIER1   \n",
       "rs12884468                           PPP2R3C; KIAA0391; PSMA6   \n",
       "rs2020854   CS (overlapping); ERBB3; BAZ2A; IL23A; ATP5F1B...   \n",
       "rs33980500                            REV3L; TRAF3IP2; MFSD4B   \n",
       "rs34725611                                        ICAM1; TYK2   \n",
       "rs4921482                                                TTC1   \n",
       "rs715285    P4HA2; IRF1; PDLIM4; RAPGEF6; SLC22A4; SLC22A5...   \n",
       "rs7552167   STPG1; NIPAL3; RCAN3; SRRM1; IL22RA1; GRHL3; C...   \n",
       "rs76956521  CD74; NDST1; RBM22; DCTN4; TNIP1 (overlapping)...   \n",
       "\n",
       "                                                      GM12878  \\\n",
       "loci                                                            \n",
       "rs12044149                                            SLC35D1   \n",
       "rs12884468                                                      \n",
       "rs2020854   CS; BAZ2A; IL23A; ATP5F1B; PTGES3; TIMELESS; G...   \n",
       "rs33980500                                    REV3L; TRAF3IP2   \n",
       "rs34725611                                              ICAM1   \n",
       "rs4921482                                                TTC1   \n",
       "rs715285                                                        \n",
       "rs7552167                                                       \n",
       "rs76956521                          CD74; TNIP1; RPS14; ATOX1   \n",
       "\n",
       "                                                   hacat_stim  \\\n",
       "loci                                                            \n",
       "rs12044149                                                      \n",
       "rs12884468  PPP2R3C (hacat_stim_2,hacat_stim only), TAD le...   \n",
       "rs2020854   CS (all), TAD level:3; BAZ2A (hacat_stim_2 onl...   \n",
       "rs33980500  REV3L (hacat_stim_2,hacat_stim only), TAD leve...   \n",
       "rs34725611                                                      \n",
       "rs4921482                 TTC1 (hacat_stim only), TAD level:1   \n",
       "rs715285    P4HA2 (hacat_stim only), TAD level:2; RAPGEF6 ...   \n",
       "rs7552167   STPG1 (all), TAD level:4; NIPAL3 (all), TAD le...   \n",
       "rs76956521  NDST1 (hacat_stim only), TAD level:1; TNIP1 (h...   \n",
       "\n",
       "                                                 hacat_unstim  \\\n",
       "loci                                                            \n",
       "rs12044149                                                      \n",
       "rs12884468  PPP2R3C (hacat_unstim_2,hacat_unstim only), TA...   \n",
       "rs2020854   CS (all), TAD level:3; TIMELESS (hacat_unstim_...   \n",
       "rs33980500  REV3L (hacat_unstim_2,hacat_unstim only), TAD ...   \n",
       "rs34725611                                                      \n",
       "rs4921482               TTC1 (hacat_unstim only), TAD level:1   \n",
       "rs715285    IRF1 (hacat_unstim only), TAD level:1; PDLIM4 ...   \n",
       "rs7552167   STPG1 (all), TAD level:3; NIPAL3 (all), TAD le...   \n",
       "rs76956521  TNIP1 (hacat_unstim_2,hacat_unstim only), TAD ...   \n",
       "\n",
       "                                                         myla  \\\n",
       "loci                                                            \n",
       "rs12044149                                                      \n",
       "rs12884468                                                      \n",
       "rs2020854   CS (all), TAD level:1; IL23A (myla only), TAD ...   \n",
       "rs33980500                                                      \n",
       "rs34725611  ICAM1 (myla_1,myla only), TAD level:1; TYK2 (m...   \n",
       "rs4921482                                                       \n",
       "rs715285    IRF1 (all), TAD level:1; SLC22A5 (myla only), ...   \n",
       "rs7552167   STPG1 (all), TAD level:3; NIPAL3 (all), TAD le...   \n",
       "rs76956521  CD74 (myla_1,myla only), TAD level:outside tad...   \n",
       "\n",
       "                                                      naive_T  \n",
       "loci                                                           \n",
       "rs12044149  SLC35D1 (all); GADD45A (naive_T_2 only); PDE4B...  \n",
       "rs12884468                                                     \n",
       "rs2020854   CS (all); ERBB3 (all); BAZ2A (all); IL23A (all...  \n",
       "rs33980500                                                     \n",
       "rs34725611                                                     \n",
       "rs4921482                       TTC1 (naive_T_1,naive_T only)  \n",
       "rs715285                                 FNIP1 (naive_T only)  \n",
       "rs7552167   STPG1 (all); NIPAL3 (naive_T only); SRRM1 (all...  \n",
       "rs76956521  CD74 (all); DCTN4 (naive_T_1,naive_T only); TN...  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# name your files with FULL_NAME and if you have replicates use FULL_NAME_N with N = 1,2...\n",
    "names = [\"hacat_stim_1\",\"hacat_stim_2\",\"hacat_unstim_1\",\"hacat_unstim_2\",\"myla_1\",\"myla_2\",\"naive_T_1\",\"naive_T_2\",\"GM12878\",\"hacat_stim\",\"hacat_unstim\",\"myla\",\"naive_T\",]\n",
    "# give the names of the full(combined samples)\n",
    "full_names = [\"GM12878\",\"hacat_stim\",\"hacat_unstim\",\"myla\",\"naive_T\"]\n",
    "tad_samples = [\"hacat_stim\",\"hacat_unstim\",\"myla\"]\n",
    "\n",
    "\n",
    "\n",
    "def create_result_row(df):\n",
    "    def _test_replicated(row,cond):\n",
    "        reps = [x for x in names if cond in x]\n",
    "        presences = [not np.isnan(row[x]) for x in reps]\n",
    "        if all(presences):\n",
    "            return \"all\"\n",
    "        elif not any(presences):\n",
    "            return False\n",
    "        else:\n",
    "            idx = np.where(presences)[0]\n",
    "            return f\"{', '.join(np.array(reps)[idx])} only\"\n",
    "        print(\"missed\")\n",
    "        return \"missed\"\n",
    "\n",
    "    def _tad_string(tad):\n",
    "        if tad in [1.0,2.0,3.0,4.0,5.0]:\n",
    "            return int(tad)\n",
    "        elif tad == 0.0:\n",
    "            return \"outside tad\"\n",
    "        return \"not found\"\n",
    "\n",
    "    def _overlapping(row):\n",
    "        if (row[full_names] == 1).any():\n",
    "            return \" (overlapping)\"\n",
    "        else:\n",
    "            return \"\"\n",
    "        \n",
    "    sample_with_replicates = [x for x in full_names if any(x + \"_\" in s for s in names)]\n",
    "\n",
    "    genes_all = {key:[] for key in [\"combined\"] + full_names}\n",
    "    for idx, row in df.iterrows():\n",
    "        genes_all[\"combined\"].append(f\"{row['gene_name']}{_overlapping(row)}\")\n",
    "        for condition in sample_with_replicates:\n",
    "            replicated = _test_replicated(row,condition)\n",
    "            if replicated:\n",
    "                genes_all[condition].append(f\"{row['gene_name']} ({replicated})\")\n",
    "                if condition in tad_samples:\n",
    "                    genes_all[condition][-1] = genes_all[condition][-1] + (f\", TAD level:{_tad_string(row['TAD_level_' + condition])}\")\n",
    "        for condition in list(set(full_names) - set(sample_with_replicates)):\n",
    "            if not np.isnan(row[condition]): \n",
    "                genes_all[condition].append(f\"{row['gene_name']}\")\n",
    "                if condition in tad_samples:\n",
    "                    genes_all[condition][-1] = genes_all[condition][-1] + (f\", TAD level:{_tad_string(row['TAD_level_' + condition])}\")\n",
    "    for key in genes_all.keys():\n",
    "        genes_all[key] = [\"; \".join(genes_all[key])]\n",
    "    return pd.DataFrame(genes_all)\n",
    "\n",
    "\n",
    "genes_dfs_TADs[\"PsA\"].groupby(\"loci\").apply(create_result_row).reset_index(level=-1, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_per_loci = {}\n",
    "for disease in snp_names:\n",
    "    genes_per_loci[disease] = genes_dfs_TADs[disease].groupby(\"loci\").apply(create_result_row).reset_index(level=-1, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,df in genes_per_loci.items():\n",
    "    df.to_csv(\n",
    "        os.path.join(output_folder, \"FINAL_genes_by_loci_\" + key + \".csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(os.path.join(output_folder,'genes_by_loci_all.xlsx'), engine='xlsxwriter')\n",
    "workbook=writer.book\n",
    "wrap = workbook.add_format({'text_wrap': True})\n",
    "\n",
    "proper_names = {key: value for key, value in zip(snp_names,full_names)}\n",
    "for key,df in genes_per_loci.items():\n",
    "    df.to_excel(writer, sheet_name = proper_names[key])\n",
    "    writer.sheets[proper_names[key]].set_column('A:A', 10)\n",
    "    writer.sheets[proper_names[key]].set_column('B:G', 35, wrap)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
